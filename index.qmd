---
title: "Missing Data and Imputation Methods"
author: "Ruchith Chippari"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

What articles did you read this week? For full credit, you must provide a summary of at least two articles.
Your Answer:
1. Self-perceived quality of life predicts mortality risk better than a multi-biomarker panel, but the combination of both does best
Summary: Studies indicate that self-reported quality of life is a more accurate indicator of mortality risk than a multi-biomarker panel by itself. On the other hand, the predictive potential is greatly increased when combined. Biomarker panels provide objective physiological insights, whereas quality of life (QoL) reflects subjective judgments of general well-being. Superior prediction accuracy is probably produced by the combination of subjective and objective indicators, which together capture a more complete picture of health conditions. This emphasizes how crucial it is to incorporate both factual biological markers and subjective self-evaluations when determining mortality risk. A comprehensive understanding of a person's health is also provided by such an approach, which improves predicted accuracy and allows for more focused interventions and better health outcomes. Therefore, taking advantage of the complementing qualities of both subjective and objective indicators presents a viable way to improve mortality risk prediction and advance techniques for individualized healthcare.

 

2. Bias in trials comparing paired continuous tests can cause researchers to choose the wrong screening modality

Summary: Researcher bias could cause them to choose an unsuitable screening technique in trials comparing matched continuous tests for screening modalities. Biases in the evaluation of these tests may result from patient selection, measurement error, or data analysis techniques. These biases have the potential to distort outcomes, favoring one test over another. As a result, due to biased study design or analysis, researchers may mistakenly favor a screening technique that appears superior. Strict trial designs, meticulous patient selection, and reliable statistical techniques are essential to reducing this problem. The dependability of results can also be verified by performing sensitivity analysis and validating them through independent research. Reducing prejudice and fostering informed decision-making about the choice of screening modalities can both be facilitated by assuring transparency in reporting procedures and outcomes. In general, resolving trial biases is crucial to preventing the use of less-than-ideal screening techniques.



